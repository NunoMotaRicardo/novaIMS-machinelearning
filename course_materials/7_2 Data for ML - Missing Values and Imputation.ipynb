{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bcfbeca",
   "metadata": {},
   "source": [
    "## Cleaning Data For Machine Learning\n",
    "\n",
    "This tutorial is based upon the textbook:\n",
    "\n",
    "Walker, M. (2022). Data Cleaning and Exploration with Machine Learning. Pakt Publishing Ltd.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583d13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7d3d6",
   "metadata": {},
   "source": [
    "## Missing values - more of a problem than you think\n",
    "\n",
    "Missing values are one of the trickiest issues in data science because they can bias results in ways that aren’t always obvious. The biggest concern is when values are not missing at random—for example, if people with lower education are less likely to report their earnings, the missingness itself is correlated with the variable of interest. In such cases, simply ignoring or deleting missing values could distort your analysis.\n",
    "\n",
    "Once missing values are identified, the challenge becomes deciding how to handle them. There is no single correct approach—different strategies make sense depending on the context.\n",
    "* Deletion (removing rows or columns with too many missing values) can be acceptable if the dataset is large and the missingness is small or random.\n",
    "* Simple imputation, such as filling with the mean, median, or mode, is quick but risks underestimating variability.\n",
    "* Conditional imputation, such as using group-specific means (e.g., mean within a category) or time-series methods like forward/backward filling, often provides more meaningful estimates.\n",
    "* More advanced methods, like regression-based imputation or K-nearest neighbors (KNN) imputation, exploit multivariate relationships in the data to generate plausible replacements.\n",
    "\n",
    "Several important considerations are often overlooked. First, missing data handling should always be done after the train–test split to avoid leakage—statistics used for imputation (like means or regression models) must come from the training data only. Second, no single method works best in all cases: deletion, simple imputation, and advanced imputation are all tools that should be chosen depending on sample size, the amount of missingness, and the mechanism causing missingness (random, systematic, or related to unobserved factors).\n",
    "\n",
    "Finally, it’s crucial to remember that imputation introduces uncertainty—good practice is to assess the sensitivity of results by comparing multiple imputation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a320035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls97 = pd.read_csv(\"nls97b.csv\")\n",
    "nls97.set_index(\"personid\", inplace=True)\n",
    "covidtotals = pd.read_csv(\"covidtotals.csv\")\n",
    "covidtotals.set_index(\"iso_code\", inplace=True)\n",
    "\n",
    "covidtotals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed7016",
   "metadata": {},
   "source": [
    "# Finding\n",
    "We will count the number of missing values for columns that we may use as\n",
    "features. We can use the isnull method to test whether each feature value is\n",
    "missing. It will return True if the value is missing and False if not. Then, we\n",
    "can use sum to count the number of True values since sum will treat each True\n",
    "value as 1 and each False value as 0. We use axis=0 to sum over the rows for\n",
    "each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2204afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "population_density     15\n",
       "aged_65_older          33\n",
       "gdp_per_capita         28\n",
       "life_expectancy         4\n",
       "diabetes_prevalence    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demovars = ['population_density','aged_65_older',\n",
    "   'gdp_per_capita','life_expectancy','diabetes_prevalence']\n",
    "covidtotals[demovars].isnull().sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa083000",
   "metadata": {},
   "source": [
    "If we want the number of missing values for each row, we can specify axis=1\n",
    "when summing. The following code creates a Series, demovarsmisscnt, with\n",
    "the number of missing values for the demographic features for each country. 181\n",
    "countries have values for all of the features, 11 are missing values for four of the five\n",
    "features, and three are missing values for all of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7298156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    181\n",
       "1     15\n",
       "2      6\n",
       "3      5\n",
       "4     11\n",
       "5      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demovarsmisscnt = covidtotals[demovars].isnull().sum(axis=1)\n",
    "demovarsmisscnt.value_counts().sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d05cae",
   "metadata": {},
   "source": [
    "Let's take a look at a few of the countries with four or more missing values. There is\n",
    "very little demographic data available for these countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16bcf358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>population_density</th>\n",
       "      <th>aged_65_older</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>diabetes_prevalence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AIA</th>\n",
       "      <td>Anguilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES</th>\n",
       "      <td>Bonaire Sint Eustatius and Saba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COK</th>\n",
       "      <td>Cook Islands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLK</th>\n",
       "      <td>Falkland Islands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGY</th>\n",
       "      <td>Guernsey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JEY</th>\n",
       "      <td>Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSR</th>\n",
       "      <td>Montserrat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIU</th>\n",
       "      <td>Niue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCN</th>\n",
       "      <td>Pitcairn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHN</th>\n",
       "      <td>Saint Helena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYR</th>\n",
       "      <td>Syria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TWN</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAT</th>\n",
       "      <td>Vatican</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WLF</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 location  population_density  aged_65_older  \\\n",
       "iso_code                                                                       \n",
       "AIA                              Anguilla                 NaN            NaN   \n",
       "BES       Bonaire Sint Eustatius and Saba                 NaN            NaN   \n",
       "COK                          Cook Islands                 NaN            NaN   \n",
       "FLK                      Falkland Islands                 NaN            NaN   \n",
       "GGY                              Guernsey                 NaN            NaN   \n",
       "JEY                                Jersey                 NaN            NaN   \n",
       "MSR                            Montserrat                 NaN            NaN   \n",
       "NIU                                  Niue                 NaN            NaN   \n",
       "PCN                              Pitcairn                 NaN            NaN   \n",
       "SHN                          Saint Helena                 NaN            NaN   \n",
       "SYR                                 Syria                 NaN            NaN   \n",
       "TWN                                Taiwan                 NaN            NaN   \n",
       "VAT                               Vatican                 NaN            NaN   \n",
       "WLF                     Wallis and Futuna                 NaN            NaN   \n",
       "\n",
       "          gdp_per_capita  life_expectancy  diabetes_prevalence  \n",
       "iso_code                                                        \n",
       "AIA                  NaN               82                  NaN  \n",
       "BES                  NaN               78                  NaN  \n",
       "COK                  NaN               76                  NaN  \n",
       "FLK                  NaN               81                  NaN  \n",
       "GGY                  NaN              NaN                  NaN  \n",
       "JEY                  NaN              NaN                  NaN  \n",
       "MSR                  NaN               74                  NaN  \n",
       "NIU                  NaN               74                  NaN  \n",
       "PCN                  NaN              NaN                  NaN  \n",
       "SHN                  NaN               81                  NaN  \n",
       "SYR                  NaN               73                  NaN  \n",
       "TWN                  NaN               80                  NaN  \n",
       "VAT                  NaN               75                  NaN  \n",
       "WLF                  NaN               80                  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covidtotals.loc[demovarsmisscnt>=4, ['location'] + demovars]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9147d",
   "metadata": {},
   "source": [
    "Let's also check missing values for total cases and deaths. 29 countries have missing\n",
    "values for cases per million in population, and 36 have missing deaths per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9960990c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    185\n",
       "1      7\n",
       "2     29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the cumulative columns for missing\n",
    "totvars = ['location','total_cases_mill','total_deaths_mill']\n",
    "covidtotals[totvars].isnull().sum(axis=0)\n",
    "totvarsmisscnt = covidtotals[totvars].isnull().sum(axis=1)\n",
    "totvarsmisscnt.value_counts().sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9edb3",
   "metadata": {},
   "source": [
    "### Coded missing values\n",
    "\n",
    "ometimes, we have logical missing values that we need to transform into actual\n",
    "missing values. This happens when the dataset designers use valid values as codes\n",
    "for missing values. These are often values such as 9, 99, or 999, based on the\n",
    "allowable number of digits for the variable. Or it might be a more complicated\n",
    "coding scheme where there are codes for different reasons for there being missings.\n",
    "For example, in the NLS dataset, the codes reveal why the respondent did not\n",
    "provide an answer for a question: -3 is an invalid skip, -4 is a valid skip, and -5 is\n",
    "a non-interview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6432d6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "motherhighgrade\n",
       "-3    523\n",
       "-4    165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set logical missings to actual missings\n",
    "nlsparents = nls97.iloc[:,-4:]\n",
    "nlsparents.shape\n",
    "nlsparents.loc[nlsparents.motherhighgrade.between(-5,-1), 'motherhighgrade'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720404f",
   "metadata": {},
   "source": [
    "For our analysis, the reason why there is a non-response is not important. Let's just\n",
    "count the number of non-responses for each of the features, regardless of the reason\n",
    "for the non-response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350dd142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "motherage           608\n",
       "parentincome       2396\n",
       "fatherhighgrade    1856\n",
       "motherhighgrade     688\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlsparents.replace(list(range(-5,0)), np.nan, inplace=True)\n",
    "nlsparents.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebbbc0",
   "metadata": {},
   "source": [
    "## Cleaning missing values\n",
    "In this section, we'll go over some of the most straightforward approaches for handling\n",
    "missing values. This includes dropping observations where there are missing values;\n",
    "assigning a sample-wide summary statistic, such as the mean, to the missing values; and\n",
    "assigning values based on the mean value for an appropriate subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1bc8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (8984, 8)\n",
      "satverbal                7578\n",
      "satmath                  7577\n",
      "gpaoverall               2980\n",
      "gpaenglish               3186\n",
      "gpamath                  3218\n",
      "gpascience               3300\n",
      "highestdegree              31\n",
      "highestgradecompleted    2321\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# set up school record and demographic data frames from the NLS data\n",
    "schoolrecordlist = ['satverbal','satmath','gpaoverall','gpaenglish',\n",
    "  'gpamath','gpascience','highestdegree','highestgradecompleted']\n",
    "\n",
    "schoolrecord = nls97[schoolrecordlist]\n",
    "print(f\"Shape: {schoolrecord.shape}\")\n",
    "# check the school record data for missings\n",
    "print(schoolrecord.isnull().sum(axis=0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4303584",
   "metadata": {},
   "source": [
    "We can create a Series, misscnt, that specifies the number of missing features\n",
    "for each observation with misscnt = schoolrecord.isnull().\n",
    "sum(axis=1). 946 observations have seven missing values for the educational\n",
    "data, while 11 are missing values for all eight features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a73b3a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1087\n",
      "1     312\n",
      "2    3210\n",
      "3    1102\n",
      "4     176\n",
      "5     101\n",
      "6    2039\n",
      "7     946\n",
      "8      11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "misscnt = schoolrecord.isnull().sum(axis=1)\n",
    "print(misscnt.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ccda50",
   "metadata": {},
   "source": [
    "Let's drop observations that have missing values for seven or more features out of\n",
    "eight. We can accomplish this by setting the thresh parameter of dropna to 2.\n",
    "This will drop observations that have fewer than two non-missing values; that is, 0\n",
    "or 1 non-missing values. We get the expected number of observations after using\n",
    "dropna; that is, 8,984 - 946 - 11 = 8,027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc174e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8027, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schoolrecord = schoolrecord.dropna(thresh=2)\n",
    "schoolrecord.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0ba92",
   "metadata": {},
   "source": [
    "# Simple replacement\n",
    "\n",
    "The most straightforward approach is to assign the overall mean for gpaoverall\n",
    "to the missing values. The following code uses the pandas Series fillna method\n",
    "to assign all missing values of gpaoverall to the mean value of the Series. The\n",
    "first argument to fillna is the value you want for all missing values – in this case,\n",
    "schoolrecord.gpaoverall.mean().\n",
    "Note that we need to remember to set\n",
    "the inplace parameter to True to overwrite the existing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772f395a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean      282\n",
       "std        62\n",
       "count   6,004\n",
       "Name: gpaoverall, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign mean values to missings\n",
    "schoolrecord.gpaoverall.agg(['mean','std','count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dcf3f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "mean      282\n",
      "std        53\n",
      "count   8,027\n",
      "Name: gpaoverall, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "schoolrecord[\"gpaoverall\"] = schoolrecord[\"gpaoverall\"].fillna(\n",
    "    schoolrecord[\"gpaoverall\"].mean()\n",
    ")\n",
    "\n",
    "print(schoolrecord.gpaoverall.isnull().sum())\n",
    "print(schoolrecord.gpaoverall.agg(['mean','std','count']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e15e2f",
   "metadata": {},
   "source": [
    "The mean has not changed. However, there is a substantial reduction in the standard\n",
    "deviation, from 61.6 to 53.3. This is one of the disadvantages of using the dataset's\n",
    "mean for all missing values.\n",
    "\n",
    "### Forward fill\n",
    "The NLS data also has a fair number of missing values for wageincome. \n",
    "Rather than assigning the mean value of wageincome to the missings, we could\n",
    "use another common technique for imputing values: we could assign the nearest\n",
    "non-missing value from a preceding observation. The ffill option of fillna\n",
    "will do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf299b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3893\n",
      "mean    49,477\n",
      "std     40,678\n",
      "count    5,091\n",
      "Name: wageincome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# use forward fill\n",
    "wageincome = nls97.wageincome.copy(deep=True)\n",
    "print(wageincome.isnull().sum())\n",
    "print(wageincome.agg(['mean','std','count']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b653d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "mean    49,549\n",
      "std     40,014\n",
      "count    8,984\n",
      "Name: wageincome, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_28340\\2023583247.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  wageincome.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "wageincome.fillna(method='ffill', inplace=True)\n",
    "print(wageincome.isnull().sum())\n",
    "print(wageincome.agg(['mean','std','count']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14a4ef",
   "metadata": {},
   "source": [
    "We could have done a backward fill instead by setting the method parameter of\n",
    "fillna to bfill. This sets missing values to the nearest following value. This\n",
    "produces the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a5698d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean    49,419\n",
      "std     41,112\n",
      "count    8,984\n",
      "Name: wageincome, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\AppData\\Local\\Temp\\ipykernel_28340\\4197383777.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  wageincome.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "wageincome = nls97.wageincome.copy(deep=True)\n",
    "wageincome.fillna(method='bfill', inplace=True)\n",
    "print(wageincome.agg(['mean','std','count']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0c474",
   "metadata": {},
   "source": [
    "If missing values are randomly distributed, then forward or backward filling has one\n",
    "advantage over using the mean: it is more likely to approximate the distribution of\n",
    "the non-missing values for the feature. Notice that the standard deviation did not\n",
    "drop substantially.\n",
    "There are times when it makes sense to base our imputation of values on the mean\n",
    "or median value for similar observations; say, those that have the same value for a\n",
    "related feature. If we are imputing values for feature X1, and X1 is correlated with\n",
    "X2, we can use the relationship between X1 and X2 to impute a value for X1 that\n",
    "may make more sense than the dataset's mean. This is pretty straightforward when\n",
    "X2 is categorical. In this case, we can impute the mean value of X1 for the associated\n",
    "value of X2.\n",
    "\n",
    "### Using groups\n",
    "\n",
    "In the NLS DataFrame, weeks worked in 2017 correlates with the highest degree\n",
    "earned. The following code shows how the mean value of weeks worked changes\n",
    "with degree attainment. The mean for weeks worked is 39, but it is much lower for\n",
    "those without a degree (28.72) and much higher for those with a professional degree\n",
    "(47.20). In this case, it may be a better choice to assign 28.72 to the missing values\n",
    "for weeks worked for individuals who have not attained a degree, rather than 39:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e354b5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.01664167916042\n",
      "highestdegree\n",
      "0. None           29\n",
      "1. GED            35\n",
      "2. High School    38\n",
      "3. Associates     40\n",
      "4. Bachelors      44\n",
      "5. Masters        45\n",
      "6. PhD            44\n",
      "7. Professional   47\n",
      "Name: weeksworked17, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# fill missings with the average by group\n",
    "print(nls97.weeksworked17.mean())\n",
    "print(nls97.groupby(['highestdegree'])['weeksworked17'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ae80b",
   "metadata": {},
   "source": [
    "The following code assigns the mean value of weeks worked across observations\n",
    "with the same degree attainment level, for those observations missing weeks\n",
    "worked. We do this by using groupby to create a groupby DataFrame,\n",
    "groupby(['highestdegree'])['weeksworked17']. Then, we use\n",
    "fillna within apply to fill those missing values with the mean for the highest\n",
    "degree group. Notice that we make sure to only do this imputation for observations\n",
    "where the highest degree is not missing, ~nls97.highestdegree.isnull().\n",
    "We will still have missing values for observations that are missing both the highest\n",
    "degree and weeks worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013e8420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weeksworked17imp</th>\n",
       "      <th>weeksworked17</th>\n",
       "      <th>highestdegree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100061</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>2. High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100139</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2. High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0. None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100292</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4. Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100583</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2. High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>2. High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100931</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>3. Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101089</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2. High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101122</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2. High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101132</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0. None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weeksworked17imp  weeksworked17   highestdegree\n",
       "personid                                                 \n",
       "100061                  48             48  2. High School\n",
       "100139                  52             52  2. High School\n",
       "100284                   0              0         0. None\n",
       "100292                  44            NaN    4. Bachelors\n",
       "100583                  52             52  2. High School\n",
       "100833                  47             47  2. High School\n",
       "100931                  52             52   3. Associates\n",
       "101089                  52             52  2. High School\n",
       "101122                  38            NaN  2. High School\n",
       "101132                  44             44         0. None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = nls97.groupby(\"highestdegree\")[\"weeksworked17\"].mean()\n",
    "nls97[\"weeksworked17imp\"] = nls97[\"weeksworked17\"].fillna(\n",
    "    nls97[\"highestdegree\"].map(means)\n",
    ")\n",
    "nls97[['weeksworked17imp','weeksworked17',\n",
    "'highestdegree']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512200c",
   "metadata": {},
   "source": [
    "These imputation strategies – removing observations with missing values, assigning a\n",
    "dataset's mean or median, using forward or backward filling, or using a group mean for\n",
    "a correlated feature – are fine for many predictive analytics projects. They work best\n",
    "when the missing values are not correlated with the target. When that is true, imputing\n",
    "values allows us to retain the other information from those observations without biasing\n",
    "our estimates.\n",
    "\n",
    "## Regression based imputation\n",
    "\n",
    "Regression imputation is a method for handling missing values by predicting them with a regression model built from other correlated features. Instead of filling missing values with an overall mean or a group mean, regression imputation leverages multiple predictors to produce more informed estimates. The simplest version, **deterministic regression imputation**, replaces missing values with predictions that lie exactly on the regression line. This ensures consistency with the model but artificially reduces variability in the data, since the imputed values are \"too perfect.\" To address this, **stochastic regression imputation** adds a random error term (drawn from the model’s residuals) to the predicted values, preserving some of the natural variation.\n",
    "\n",
    "Regression imputation is most useful when the variable with missing data is strongly related to several other features. It can yield better imputations than single-statistic methods (like mean or median imputation) because it respects relationships between variables. However, students should be aware of several caveats:\n",
    "\n",
    "* **Variance reduction**: Deterministic regression imputation can underestimate variability, making the imputed variable look less dispersed than it truly is. This can bias downstream analyses.\n",
    "* **Stochastic correction**: Adding a residual component helps maintain variance, but it introduces randomness, which can complicate reproducibility unless carefully managed (e.g., with fixed random seeds).\n",
    "* **Risk of overfitting**: The regression model used for imputation must be trained **only on the training data**, otherwise information leaks from the test set.\n",
    "* **Distributional mismatch**: If the regression model is misspecified (e.g., assuming linearity when the relationship is nonlinear), imputations may distort the data distribution.\n",
    "* **Computational cost**: Compared to simple imputation, regression methods require extra modeling and computation.\n",
    "\n",
    "In practice, regression imputation works well when the relationships between features are stable and well understood. For large datasets or where missingness is limited, simpler methods may be more practical. For smaller datasets or when accuracy is critical, regression or even more advanced approaches like multiple imputation or machine-learning–based imputers (e.g., random forest, KNN) may be preferred.\n",
    "\n",
    "Regression imputation is a powerful tool because it uses information from multiple predictors, but you must be cautious about variance shrinkage, possible overfitting, and data leakage. Stochastic regression imputation often provides a better balance by preserving variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1503f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8984 entries, 100061 to 999963\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   wageincome     5091 non-null   float64\n",
      " 1   highestdegree  8953 non-null   object \n",
      " 2   weeksworked16  7068 non-null   float64\n",
      " 3   parentincome   8984 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 350.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# check correlations with wageincome\n",
    "nls97[['wageincome','highestdegree','weeksworked16','parentincome']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e2b33",
   "metadata": {},
   "source": [
    "Let's convert the highestdegree feature into a numeric value. This will make the\n",
    "analysis we'll be doing in the rest of this section easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99981fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highestdegree    hdegnum\n",
       "0. None          0           953\n",
       "1. GED           1          1146\n",
       "2. High School   2          3667\n",
       "3. Associates    3           737\n",
       "4. Bachelors     4          1673\n",
       "5. Masters       5           603\n",
       "6. PhD           6            54\n",
       "7. Professional  7           120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls97['hdegnum'] = nls97.highestdegree.str[0:1].astype('float')\n",
    "nls97.groupby(['highestdegree','hdegnum']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a819e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace invalid parent income values (-5 to -1) with NaN (mark them as missing)\n",
    "nls97 = nls97.copy()\n",
    "nls97['parentincome'] = nls97['parentincome'].mask(\n",
    "    nls97['parentincome'].between(-5, -1), np.nan\n",
    ")\n",
    "\n",
    "# Compute correlations among income, education, work experience, and parent income\n",
    "corr_matrix = nls97[['wageincome', 'hdegnum', 'weeksworked16', 'parentincome']].corr()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403650e7",
   "metadata": {},
   "source": [
    "We should check whether observations with missing values for wage income are\n",
    "different in some important way from those with non-missing values. The following\n",
    "code shows that these observations have significantly lower degree attainment\n",
    "levels, parental income, and weeks worked. This is a clear case where assigning the\n",
    "overall mean would not be the best choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b64a5039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  hdegnum       parentincome       weeksworked16      \n",
      "                     mean count         mean count          mean count\n",
      "missingwageincome                                                     \n",
      "0                       3  5072       48,409  3803            48  5052\n",
      "1                       2  3881       43,566  2785            16  2016\n"
     ]
    }
   ],
   "source": [
    "# Create an indicator for missing wage income: 1 if missing, 0 otherwise\n",
    "nls97 = nls97.assign(\n",
    "    missingwageincome = nls97['wageincome'].isna().astype(int)\n",
    ")\n",
    "\n",
    "# Compare characteristics of people with and without missing wage income\n",
    "# (average and count of degree, parent income, weeks worked)\n",
    "missing_profile = (\n",
    "    nls97\n",
    "    .groupby('missingwageincome')[['hdegnum', 'parentincome', 'weeksworked16']]\n",
    "    .agg(['mean','count'])\n",
    ")\n",
    "\n",
    "print(missing_profile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef3d48",
   "metadata": {},
   "source": [
    "Let's try regression imputation instead. Let's start by cleaning up the data a little\n",
    "bit more. We can replace the missing weeksworked16 and parentincome\n",
    "values with their means. We should also collapse hdegnum into those attaining less\n",
    "than a college degree, those with a college degree, and those with a post-graduate\n",
    "degree. We can set those up as dummy variables, with 0 or 1 values when they're\n",
    "False or True, respectively. This is a tried and true method for treating categorical\n",
    "data in regression analysis as it allows us to estimate different y intercepts based on\n",
    "group membership:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8130a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in predictors with their mean (avoids dropping rows later)\n",
    "nls97['weeksworked16'] = nls97['weeksworked16'].fillna(nls97['weeksworked16'].mean())\n",
    "nls97['parentincome']  = nls97['parentincome'].fillna(nls97['parentincome'].mean())\n",
    "\n",
    "# Create education dummy variables while preserving missingness:\n",
    "# We use np.where with a mask `~nls97['hdegnum'].isna()` so that when hdegnum is NaN,\n",
    "# the dummy remains NaN (rather than 0, which would incorrectly imply \"not that level\").\n",
    "\n",
    "nls97['degltcol'] = (nls97['hdegnum'] <= 2).astype(int)        # less than college\n",
    "nls97['degcol']   = (nls97['hdegnum'].between(3, 4)).astype(int) # college degree\n",
    "nls97['degadv']   = (nls97['hdegnum'] > 4).astype(int)         # advanced degree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "408251f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weeksworked16</th>\n",
       "      <th>parentincome</th>\n",
       "      <th>degcol</th>\n",
       "      <th>degadv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100061</th>\n",
       "      <td>48</td>\n",
       "      <td>7,400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100139</th>\n",
       "      <td>53</td>\n",
       "      <td>57,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100284</th>\n",
       "      <td>47</td>\n",
       "      <td>50,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100292</th>\n",
       "      <td>4</td>\n",
       "      <td>62,760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100583</th>\n",
       "      <td>53</td>\n",
       "      <td>18,500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weeksworked16  parentincome  degcol  degadv\n",
       "personid                                             \n",
       "100061               48         7,400       0       0\n",
       "100139               53        57,000       0       0\n",
       "100284               47        50,000       0       0\n",
       "100292                4        62,760       1       0\n",
       "100583               53        18,500       0       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 4. Regression Helper Function ---\n",
    "def getlm(df, ycolname, xcolnames):\n",
    "    \"\"\"\n",
    "    Fits an OLS regression with ycolname as dependent variable\n",
    "    and xcolnames as predictors. Returns coefficients and model.\n",
    "    \"\"\"\n",
    "    # Keep only y and predictors, drop missing rows\n",
    "    model_df = df[[ycolname] + xcolnames].dropna()\n",
    "    y = model_df[ycolname]\n",
    "    X = sm.add_constant(model_df[xcolnames])  # add intercept\n",
    "    \n",
    "    # Fit linear regression\n",
    "    lm = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Collect coefficients and p-values into a DataFrame\n",
    "    coefficients = pd.DataFrame(\n",
    "        {\n",
    "            'features': ['constant'] + xcolnames,\n",
    "            'params':   lm.params.values,\n",
    "            'pvalues':  lm.pvalues.values\n",
    "        }\n",
    "    )\n",
    "    return coefficients, lm\n",
    "\n",
    "# Choose predictors and run regression\n",
    "xvars = ['weeksworked16', 'parentincome', 'degcol', 'degadv']\n",
    "nls97[xvars].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8a390",
   "metadata": {},
   "source": [
    "Now, we can use the getlm function to get the parameter estimates and the model\n",
    "summary. All of the coefficients are positive and significant at the 95% level since\n",
    "they have pvalues less than 0.05. As expected, wage income increases with the\n",
    "number of weeks worked and with parental income. Having a college degree gives a\n",
    "nearly $16K boost to earnings, compared with not having a college degree. A postgraduate degree bumps up the earnings prediction even more – almost $37K more\n",
    "than for those with less than a college degree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aaad19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients, lm = getlm(nls97, 'wageincome', xvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247ede70",
   "metadata": {},
   "source": [
    "We can use this model to impute values for wage income where they are missing.\n",
    "We need to add a constant for the predictions since our model included a constant.\n",
    "We can convert the predictions into a DataFrame and then join it with the rest of\n",
    "the NLS data. Then, we can create a new wage income feature, wageincomeimp,\n",
    "that gets the predicted value when wage income is missing, and the original wage\n",
    "income value otherwise. Let's also take a look at some of the predictions to see\n",
    "whether they make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de60d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          wageincomeimp  wageincome  weeksworked16  parentincome  degcol  \\\n",
      "personid                                                                   \n",
      "100061           12,500      12,500             48         7,400       0   \n",
      "100139          120,000     120,000             53        57,000       0   \n",
      "100284           58,000      58,000             47        50,000       0   \n",
      "100292           36,547         NaN              4        62,760       1   \n",
      "100583           30,000      30,000             53        18,500       0   \n",
      "100833           39,000      39,000             45        37,000       0   \n",
      "100931           56,000      56,000             53        60,200       1   \n",
      "101089           36,000      36,000             53        32,307       0   \n",
      "101122           35,151         NaN             39        46,362       0   \n",
      "101132                0           0             22         2,470       0   \n",
      "\n",
      "          degadv  \n",
      "personid          \n",
      "100061         0  \n",
      "100139         0  \n",
      "100284         0  \n",
      "100292         0  \n",
      "100583         0  \n",
      "100833         0  \n",
      "100931         0  \n",
      "101089         0  \n",
      "101122         0  \n",
      "101132         0  \n",
      "       wageincomeimp  wageincome\n",
      "count          8,984       5,091\n",
      "mean          42,559      49,477\n",
      "std           33,406      40,678\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for wage income using the regression model\n",
    "predict = lm.predict(sm.add_constant(nls97[xvars])).rename('pred')\n",
    "\n",
    "# add to data\n",
    "nls97 = nls97.assign(pred = lm.predict(sm.add_constant(nls97[xvars])))\n",
    "nls97['wageincomeimp'] = nls97['wageincome'].fillna(nls97['pred'])\n",
    "\n",
    "# Preview and summary \n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "preview = nls97[['wageincomeimp', 'wageincome']].join(nls97[xvars]).head(10)\n",
    "summary = nls97[['wageincomeimp','wageincome']].agg(['count','mean','std'])\n",
    "\n",
    "print(preview)\n",
    "print(summary)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b43e2",
   "metadata": {},
   "source": [
    "Stochastic regression imputation adds a normally distributed error to the\n",
    "predictions based on the residuals from our model. We want this error to have a\n",
    "mean of 0 with the same standard deviation as our residuals. We can use NumPy's\n",
    "normal function for that with np.random.normal(0, lm.resid.std(),\n",
    "nls97.shape[0]). The lm.resid.std() parameter gets us the standard\n",
    "deviation of the residuals from our model. The final parameter value, nls97.\n",
    "shape[0], indicates how many values to create; in this case, we want a value for\n",
    "every row in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3930212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Imputation (adds randomness) ---\n",
    "# Generate random noise from a normal distribution with same variance as residuals\n",
    "randomadd = np.random.normal(loc=0, scale=lm.resid.std(), size=nls97.shape[0])\n",
    "\n",
    "# Add random noise, stochastic predictions, and stochastically imputed wages\n",
    "nls97 = nls97.assign(\n",
    "    randomadd = randomadd,\n",
    "    stochasticpred = nls97['pred'] + randomadd,\n",
    "    # If wage income is missing, use stochastic prediction instead of pure prediction\n",
    "    wageincomeimpstoc = nls97['wageincome'].fillna(lambda s: nls97['stochasticpred'])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca832a",
   "metadata": {},
   "source": [
    "Regression imputation is a good way to take advantage of all the data we have to impute\n",
    "values for a feature. It is often superior to the imputation methods we examined in the\n",
    "previous section, particularly when missing values are not random. If we use stochastic\n",
    "regression imputation, we will not artificially reduce our variance.\n",
    "Before we started using machine learning for this work, this was our go-to multivariate\n",
    "approach for imputation. We now have the option of using algorithms such as KNN\n",
    "for this task, which has advantages over regression imputation in some cases. KNN\n",
    "imputation, unlike regression imputation, does not assume a linear relationship between\n",
    "features, or that those features are normally distributed. We will explore KNN imputation\n",
    "in the next section.\n",
    "\n",
    "## KNN Imputation\n",
    "\n",
    "KNN is a popular machine learning technique because it is intuitive, easy to run, and\n",
    "yields good results when there are not a large number of features and observations. For\n",
    "the same reasons, it is often used to impute missing values. As its name suggests, KNN\n",
    "identifies the k observations whose features are most similar to each observation. When\n",
    "it's used to impute missing values, KNN uses the nearest neighbors to determine what fill\n",
    "values to use.\n",
    "We can use KNN imputation to do the same imputation we did in the previous section on\n",
    "regression imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "845a35ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with at least one non-missing value: 8984\n"
     ]
    }
   ],
   "source": [
    "has_hdeg = ~nls97['hdegnum'].isna()\n",
    "\n",
    "# Replace invalid/sentinel parent income values (-5, -4, -3, -2, -1) with NaN.\n",
    "nls97['parentincome'] = nls97['parentincome'].mask(nls97['parentincome'].between(-5, -1), np.nan)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Select features to impute and build matrix\n",
    "# -----------------------------------------\n",
    "\n",
    "# Columns to include in the imputation model.\n",
    "# KNNImputer will impute missing values by looking at nearest neighbors in this feature space.\n",
    "wagedatalist = ['wageincome', 'weeksworked16', 'parentincome', 'degltcol', 'degcol', 'degadv']\n",
    "\n",
    "# Extract the working frame; ensure it exists and is numeric (KNNImputer requires floats).\n",
    "wagedata = nls97[wagedatalist].astype('float')\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Configure KNNImputer (protect against too-large k values)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# How many rows do we have with at least one non-missing value? (A rough proxy for usable rows)\n",
    "n_valid_rows = len(wagedata)\n",
    "print(f'Number of rows with at least one non-missing value: {n_valid_rows}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eeb7a3",
   "metadata": {},
   "source": [
    "We are now ready to use the fit_transform method of the KNN imputer to\n",
    "get values for all the missing values in the passed DataFrame, wagedata. fit_\n",
    "transform returns a NumPy array that contains all the non-missing values from\n",
    "wagedata, plus the imputed ones. We can convert this array into a DataFrame\n",
    "using the same index as wagedata. This will make it easy to join the data in the\n",
    "next step.\n",
    "\n",
    "We need to specify the value to use for the number of nearest neighbors, for k. We\n",
    "use a general rule of thumb for determining k – the square root of the number of\n",
    "observations divided by 2 (sqrt(N)/2). That gives us 47 for k in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce5337a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wageincomeimpknn</th>\n",
       "      <th>weeksworked16imp</th>\n",
       "      <th>parentincomeimp</th>\n",
       "      <th>degltcol</th>\n",
       "      <th>degcol</th>\n",
       "      <th>degadv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100061</th>\n",
       "      <td>12,500</td>\n",
       "      <td>48</td>\n",
       "      <td>7,400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100139</th>\n",
       "      <td>120,000</td>\n",
       "      <td>53</td>\n",
       "      <td>57,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100284</th>\n",
       "      <td>58,000</td>\n",
       "      <td>47</td>\n",
       "      <td>50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100292</th>\n",
       "      <td>61,639</td>\n",
       "      <td>4</td>\n",
       "      <td>62,760</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100583</th>\n",
       "      <td>30,000</td>\n",
       "      <td>53</td>\n",
       "      <td>18,500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>39,000</td>\n",
       "      <td>45</td>\n",
       "      <td>37,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100931</th>\n",
       "      <td>56,000</td>\n",
       "      <td>53</td>\n",
       "      <td>60,200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101089</th>\n",
       "      <td>36,000</td>\n",
       "      <td>53</td>\n",
       "      <td>32,307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101122</th>\n",
       "      <td>31,685</td>\n",
       "      <td>39</td>\n",
       "      <td>46,362</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101132</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2,470</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wageincomeimpknn  weeksworked16imp  parentincomeimp  degltcol  \\\n",
       "personid                                                                  \n",
       "100061              12,500                48            7,400         1   \n",
       "100139             120,000                53           57,000         1   \n",
       "100284              58,000                47           50,000         1   \n",
       "100292              61,639                 4           62,760         0   \n",
       "100583              30,000                53           18,500         1   \n",
       "100833              39,000                45           37,000         1   \n",
       "100931              56,000                53           60,200         0   \n",
       "101089              36,000                53           32,307         1   \n",
       "101122              31,685                39           46,362         1   \n",
       "101132                   0                22            2,470         1   \n",
       "\n",
       "          degcol  degadv  \n",
       "personid                  \n",
       "100061         0       0  \n",
       "100139         0       0  \n",
       "100284         0       0  \n",
       "100292         1       0  \n",
       "100583         0       0  \n",
       "100833         0       0  \n",
       "100931         1       0  \n",
       "101089         0       0  \n",
       "101122         0       0  \n",
       "101132         0       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_neighbors must be < number of samples to work correctly; guard against edge cases.\n",
    "k = min(47, max(1, n_valid_rows - 1))\n",
    "\n",
    "# Initialize the imputer:\n",
    "# - KNNImputer uses Euclidean distance on standardized feature space implicitly (not scaled),\n",
    "#   so be aware that features on different scales can dominate distance.\n",
    "#   (For teaching: you can standardize features first if appropriate.)\n",
    "impKNN = KNNImputer(n_neighbors=k)\n",
    "\n",
    "# Fit the imputer on the data and transform to fill in missing values.\n",
    "# Returns a NumPy array with the same shape, with imputed values where NaNs were present.\n",
    "newvalues = impKNN.fit_transform(wagedata)\n",
    "\n",
    "# Name the imputed columns.\n",
    "# For continuous vars we add 'imp' suffix; dummies are also imputed but we keep original names\n",
    "# to easily compare behavior. If you want, you can round or re-binarize imputed dummies later.\n",
    "wagedatalistimp = ['wageincomeimpknn', 'weeksworked16imp', 'parentincomeimp', 'degltcol', 'degcol', 'degadv']\n",
    "\n",
    "# Convert the imputed array back to a DataFrame, keeping the original index alignment.\n",
    "wagedataimpknn = pd.DataFrame(newvalues, columns=wagedatalistimp, index=wagedata.index)\n",
    "wagedataimpknn.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc6c4bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wageincome</th>\n",
       "      <th>weeksworked16</th>\n",
       "      <th>parentincome</th>\n",
       "      <th>degcol</th>\n",
       "      <th>degadv</th>\n",
       "      <th>wageincomeimpknn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100061</th>\n",
       "      <td>12,500</td>\n",
       "      <td>48</td>\n",
       "      <td>7,400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100139</th>\n",
       "      <td>120,000</td>\n",
       "      <td>53</td>\n",
       "      <td>57,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100284</th>\n",
       "      <td>58,000</td>\n",
       "      <td>47</td>\n",
       "      <td>50,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>62,760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61,639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100583</th>\n",
       "      <td>30,000</td>\n",
       "      <td>53</td>\n",
       "      <td>18,500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>39,000</td>\n",
       "      <td>45</td>\n",
       "      <td>37,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100931</th>\n",
       "      <td>56,000</td>\n",
       "      <td>53</td>\n",
       "      <td>60,200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101089</th>\n",
       "      <td>36,000</td>\n",
       "      <td>53</td>\n",
       "      <td>32,307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>46,362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31,685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101132</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2,470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wageincome  weeksworked16  parentincome  degcol  degadv  \\\n",
       "personid                                                            \n",
       "100061        12,500             48         7,400       0       0   \n",
       "100139       120,000             53        57,000       0       0   \n",
       "100284        58,000             47        50,000       0       0   \n",
       "100292           NaN              4        62,760       1       0   \n",
       "100583        30,000             53        18,500       0       0   \n",
       "100833        39,000             45        37,000       0       0   \n",
       "100931        56,000             53        60,200       1       0   \n",
       "101089        36,000             53        32,307       0       0   \n",
       "101122           NaN             39        46,362       0       0   \n",
       "101132             0             22         2,470       0       0   \n",
       "\n",
       "          wageincomeimpknn  \n",
       "personid                    \n",
       "100061              12,500  \n",
       "100139             120,000  \n",
       "100284              58,000  \n",
       "100292              61,639  \n",
       "100583              30,000  \n",
       "100833              39,000  \n",
       "100931              56,000  \n",
       "101089              36,000  \n",
       "101122              31,685  \n",
       "101132                   0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Inspect and compare data\n",
    "# -----------------------\n",
    "\n",
    "# Join selected imputed columns to the original selection for side-by-side viewing.\n",
    "wagedata_view = (\n",
    "    wagedata\n",
    "    .join(wagedataimpknn[['wageincomeimpknn', 'weeksworked16imp', 'parentincomeimp']])\n",
    ")\n",
    "\n",
    "# Peek at the first 10 rows of raw vs. imputed values (plus the education dummies).\n",
    "wagedata_view[['wageincome', 'weeksworked16', 'parentincome', 'degcol', 'degadv', 'wageincomeimpknn']].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fc8df97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       wageincome  wageincomeimpknn\n",
      "count       5,091             8,984\n",
      "mean       49,477            46,883\n",
      "std        40,678            32,076\n"
     ]
    }
   ],
   "source": [
    "# Simple summary statistics to compare original vs. imputed wage income.\n",
    "wage_summary = wagedata_view[['wageincome', 'wageincomeimpknn']].agg(['count', 'mean', 'std'])\n",
    "print(wage_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51e7377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wageincome</th>\n",
       "      <th>wageincomeimpknn</th>\n",
       "      <th>weeksworked16</th>\n",
       "      <th>weeksworked16imp</th>\n",
       "      <th>parentincome</th>\n",
       "      <th>parentincomeimp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100061</th>\n",
       "      <td>12,500</td>\n",
       "      <td>12,500</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>7,400</td>\n",
       "      <td>7,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100139</th>\n",
       "      <td>120,000</td>\n",
       "      <td>120,000</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>57,000</td>\n",
       "      <td>57,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100284</th>\n",
       "      <td>58,000</td>\n",
       "      <td>58,000</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>50,000</td>\n",
       "      <td>50,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>61,639</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>62,760</td>\n",
       "      <td>62,760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100583</th>\n",
       "      <td>30,000</td>\n",
       "      <td>30,000</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>18,500</td>\n",
       "      <td>18,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>39,000</td>\n",
       "      <td>39,000</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>37,000</td>\n",
       "      <td>37,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100931</th>\n",
       "      <td>56,000</td>\n",
       "      <td>56,000</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>60,200</td>\n",
       "      <td>60,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101089</th>\n",
       "      <td>36,000</td>\n",
       "      <td>36,000</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>32,307</td>\n",
       "      <td>32,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31,685</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>46,362</td>\n",
       "      <td>46,362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>2,470</td>\n",
       "      <td>2,470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wageincome  wageincomeimpknn  weeksworked16  weeksworked16imp  \\\n",
       "personid                                                                  \n",
       "100061        12,500            12,500             48                48   \n",
       "100139       120,000           120,000             53                53   \n",
       "100284        58,000            58,000             47                47   \n",
       "100292           NaN            61,639              4                 4   \n",
       "100583        30,000            30,000             53                53   \n",
       "100833        39,000            39,000             45                45   \n",
       "100931        56,000            56,000             53                53   \n",
       "101089        36,000            36,000             53                53   \n",
       "101122           NaN            31,685             39                39   \n",
       "101132             0                 0             22                22   \n",
       "\n",
       "          parentincome  parentincomeimp  \n",
       "personid                                 \n",
       "100061           7,400            7,400  \n",
       "100139          57,000           57,000  \n",
       "100284          50,000           50,000  \n",
       "100292          62,760           62,760  \n",
       "100583          18,500           18,500  \n",
       "100833          37,000           37,000  \n",
       "100931          60,200           60,200  \n",
       "101089          32,307           32,307  \n",
       "101122          46,362           46,362  \n",
       "101132           2,470            2,470  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls97 = nls97.join(wagedataimpknn[['wageincomeimpknn', 'weeksworked16imp', 'parentincomeimp']])\n",
    "nls97[['wageincome', 'wageincomeimpknn','weeksworked16', 'weeksworked16imp', 'parentincome', 'parentincomeimp']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394d1de",
   "metadata": {},
   "source": [
    "KNN does imputations without making any assumptions about the distribution of\n",
    "the underlying data. With regression imputation, the standard assumptions for linear\n",
    "regression apply – that is, that there is a linear relationship between features and that\n",
    "they are distributed normally. If this is not the case, KNN is likely a better approach for\n",
    "imputation.\n",
    "Despite these advantages, KNN imputation does have limitations. First, we must tune\n",
    "the model with an initial assumption about a good value for k, sometimes informed by\n",
    "little more than our knowledge of the size of the dataset. KNN is also computationally\n",
    "expensive and may be impractical for very large datasets. Finally, KNN imputation may\n",
    "not perform well when the correlation is weak between the feature to be imputed and the\n",
    "predictor features. An alternative to KNN for imputation, random forest imputation, can\n",
    "help us avoid the disadvantages of both KNN and regression imputation. We will explore\n",
    "random forest imputation in the next section.\n",
    "\n",
    "### Further options - Random forests for imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1221160",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
